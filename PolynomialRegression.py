import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Load the dataset
x_train = pd.read_csv('X_train.csv')
y_train = pd.read_csv('y_train.csv')
x_test = pd.read_csv('X_test.csv')
y_test = pd.read_csv('y_test.csv')

# Generate polynomial and interaction features
poly = PolynomialFeatures(degree=2, include_bias=False)
x_train_poly = poly.fit_transform(x_train)
x_test_poly = poly.transform(x_test)

# Fit the Polynomial Regression Model
poly_regressor = LinearRegression()
poly_regressor.fit(x_train_poly, y_train)

# Predicting on the test set
y_pred = poly_regressor.predict(x_test_poly)

# Evaluate the model
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f'RÂ² Score: {r2}')
print(f'Mean Squared Error: {mse}')

# Scatter plot of actual vs predicted values
plt.scatter(y_test, y_pred, color='blue')
plt.xlabel('Actual Sale Prices')
plt.ylabel('Predicted Sale Prices')
plt.title('Actual vs Predicted Sale Prices (Polynomial Regression)')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)
plt.show()
